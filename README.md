# Medical Text Classification + LLM

**â€œHuggingFace text classifier for medical descriptionsâ€**  

Web scraped ~1,220 medical descriptions from `drugs.com`, cleaned the data, and built a BERTâ€‘based text classification model. Also included a small web application for inference.  

---

## ğŸš€ Project Overview

This project aims to classify medical text descriptions (e.g. drug side effects, conditions) into categories using a fineâ€‘tuned transformer. The goals include:

- Demonstrating full pipeline: data collection â†’ cleaning â†’ modeling â†’ deployment  
- Showing experience with NLP, transformers, fine-tuning, and web serving  
- Producing a usable interface for inference  

---

## ğŸ—‚ï¸ Repository Structure

Hereâ€™s an overview of the files and what they do:

| File / Folder | Purpose |
|----------------|---------|
| `webscraper.ipynb` | Notebook which scrapes medical descriptions data from `drugs.com` |
| `onemed.csv` | The cleaned dataset of medical descriptions (labels + text) |
| `model_learning.ipynb` | Notebook for model training, evaluation, experiments |
| `webapp.py` | Flask / API code for serving model predictions via a web interface |
| `.gitignore` | Files / folders to ignore when pushing (e.g. data, temp files) |
| `.idea/` | IDE config files |

---

## ğŸ› ï¸ Tech Stack & Tools

- **Python** (pandas, numpy, scikit-learn)  
- **Transformers / Hugging Face** (for fine-tuning BERT)  
- **Flask** (or other) for web app / inference interface  
- **Jupyter Notebooks** for exploration, modeling  
- **Web scraping tools** (requests, BeautifulSoup, etc.)  

---

## ğŸ“Š Methodology & Results

### Data Collection & Cleaning  
- Scraped ~1,220 entries from `drugs.com`  
- Removed HTML tags, normalized text, handled missing data  
- Possibly created label categories (e.g. â€œside effectâ€, â€œusageâ€, â€œcontraindicationâ€)  

### Modeling & Experiments  
- Fineâ€‘tuned a **BERT** (or other transformer) model  
- Tried baseline vs advanced architectures  
- Evaluated using **accuracy**, **F1 score**, **confusion matrix**, and perhaps **precision/recall**

### Results  
- (Here youâ€™d insert your modelâ€™s metrics â€” e.g. â€œF1 = 0.89â€, â€œAccuracy = 92%â€)  
- Visualizations of error analysis, confusion matrix, etc.  
- Insights observed â€” what kinds of classes are harder, what features are important  

---

## ğŸ“± Demo / Web App Usage

You can run the web app locally (assuming dependencies installed):

```bash
pip install -r requirements.txt
python webapp.py
